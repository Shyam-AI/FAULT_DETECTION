{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'logging' has no attribute 'getLogger'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "file_contents = a_file. read()\n",
    "contents_split = file_contents. splitlines()\n",
    "print(contents_split)\n",
    "a_file. close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mAttributeError: module 'logging' has no attribute 'getLogger'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a_file = open(\"requirements.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Object Storage v/s File Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://cloudian.com/blog/object-storage-vs-file-storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_requirements()->List[str]:\n",
    "    requirement_list:List[str] = []\n",
    "    try:\n",
    "        req_file = open(\"requirements.txt\")\n",
    "        file_contents= req_file.read()\n",
    "        requirement_list= file_contents.splitlines()\n",
    "    except FileNotFoundError:\n",
    "        return \"Kindly check the file is missing\"\n",
    "    return requirement_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pymongo[srv]==4.2.0', '# pandas', '# sklearn', 'certifi', '-e .']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# req_file = open(\"requirements.txt\")\n",
    "# file_contents= req_file.read()\n",
    "# requirement_list= file_contents.splitlines()\n",
    "get_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongodb check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topics.configuration.mongo_db_connection import MongoDBClient\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mongo_db_client = MongoDBClient()\n",
    "    print(mongo_db_client.database.list_collection_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exception check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from topics.exception import TopicsException\n",
    "import sys\n",
    "\n",
    "def exception_test():\n",
    "    try:\n",
    "        x = 1/0\n",
    "    except Exception as e:\n",
    "        raise TopicsException(e, sys)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    try:\n",
    "        exception_test()\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aps_sensor.utils.main_utils import read_yaml\n",
    "file_path = \n",
    "schema_config = read_yaml(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Drift test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KstestResult(statistic=0.09090909090909091, pvalue=1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = np.arange(11)\n",
    "d2 = np.arange(10)\n",
    "\n",
    "ks_2samp(d1, d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aps_sensor.utils.main_utils import write_yaml_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_drift_report(base_df,current_df,threshold=0.05):\n",
    "    report ={}\n",
    "    for column in base_df.columns:\n",
    "        d1 = base_df[column]\n",
    "        d2  = current_df[column]\n",
    "        is_same_dist = ks_2samp(d1,d2)\n",
    "        if threshold<=is_same_dist.pvalue:\n",
    "            is_found=False\n",
    "        else:\n",
    "            is_found = True \n",
    "        report.update({column:{\n",
    "            \"p_value\":float(is_same_dist.pvalue),\n",
    "            \"drift_status\":is_found\n",
    "            \n",
    "            }})\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3325faae07c1f8479fe18c20690ab60fe50f02cb02671a31f01ebf4ea3bc0709"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
